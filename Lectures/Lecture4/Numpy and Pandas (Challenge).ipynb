{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy also supports many linear algebra operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 10 * np.random.rand(3, 3)\n",
    "A = A.astype(int)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A @ x # Matrix vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(A, x) # equivalent to above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A * x # does not work as expected! see the broadcasting section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_vector_in_subspace(A):\n",
    "    return np.dot(A, np.random.rand(A.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = generate_vector_in_subspace(A)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(np.linalg.inv(A), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.arange(1, 10).reshape(3, 3) # arange is similar to range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (A < 5)\n",
    "A[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.rand generates a random matrix of some shape\n",
    "B = np.random.rand(1, 9).reshape(3, 3)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[cond] # selects the first four elements of the matrix (by row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2])\n",
    "y = np.array([[3], [4]])\n",
    "x + y # what does this output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(1000).reshape(1000, 1)\n",
    "b = np.ones((1000, 1))\n",
    "X = np.append(x, b, axis=1)\n",
    "\n",
    "Y = 2 * x[:,0] + 4*b + np.random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Least Squares Linear Regression to find $\\hat{\\theta}$, weights on each column of $X$ such that it models $Y$. Remember, the formula for Least Squares Linear Regression is: \n",
    "\n",
    "$$X^TX\\hat{\\theta} = X^TY$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat = ...\n",
    "theta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the loss of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ...\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a commonly used data processing library. \n",
    "\n",
    "Data is stored in **DataFrame** objects, which is a collection of **Series** objects, which represent columns.\n",
    "\n",
    "We'll go over an example EDA (exploratory data analysis) and feature engineering process on some data in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = pd.read_csv('titanic/train.csv')\n",
    "titanic_test = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's do some data cleaning. Are there any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column with missing values is **Age**. One way we can deal with missing *quantitative* data is **imputing** the missing values with the mean of the column.\n",
    "\n",
    "We use the <a href=https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html>**.fillna**</a> function of Pandas to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Age'] = titanic_train['Age'].fillna(titanic_train['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next column with missing values is **Cabin**. In general, the **Cabin** column is weird, so let's investigate it further. We use the <a href=https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.unique.html>.unique</a> to look at the different values of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Cabin'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the counts of each value in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Cabin'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like each entry has maybe a Floor and a room number: however, some entries seem to have multiple cabins, and some entries are even more interesting: \"T\", \"F E69\". There are many ways to approach this data, but for now, let's just take the Floor letter from each cabin and place it into a new column.\n",
    "\n",
    "Note: this may not be the best way to use the Cabin column: if the goal is to predict if a person survived, it may be important to save not just the floor but also the cabin number---i.e. if different people stay in the same room, maybe they all survived or all died."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_train['Floor'] = titanic_train['Cabin'].apply(lambda cabin: cabin[0] if type(cabin) != float else cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Floor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Floor'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also take a look at the types of data in some of the rest of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['SibSp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Pclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Parch'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Embarked'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Columns, Inplace\n",
    "\n",
    "Above, when we said:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_train['Age'] = titanic_train['Age'].fillna(titanic_train['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had to set it equal to the column after we called **.fillna**: this is because almost all Pandas functions are **non-destructive** by default---if you're performing an operation on the column, Pandas will create a new column, rather than replace an old column.\n",
    "\n",
    "For example, the <a href=https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html>**.drop**</a> method will not remove a column from a DataFrame, it will create a copy of the DataFrame without that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['dummy'] = 1\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train.drop('dummy', axis=1).head() # axis = 1 means drop columns, not rows: if you wanted to drop rows, pass in the row index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we pass in **inplace=True**, then Pandas will delete the column in the original DataFrame: many other functions in Pandas have this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['dummy'] = 1\n",
    "titanic_train.drop('dummy', inplace=True, axis=1)\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be warned: doing things inplace is dangerous! Say, for example, it took a really long time to load in your database (maybe you had to do some web scraping, or you downloaded it directly from a URL and you lost Internet connection). If you do **drop** operations inplace, without saving the original state of the DataFrame, you could lose data.\n",
    "\n",
    "In general, it is usually a good idea to save your DataFrame in states throughout your EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the Titanic data is **categorical**: one way to deal with this kind of data so that we can do predictive modeling is **one-hot encoding**, which means we transform a column, \"Pclass\" for example, which has 3 different values into 3 different columns with 0 or 1 values, e.g. the values are 1, 2, 3, so 2 turns into [0 1 0].\n",
    "\n",
    "We use the <a href=https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html>**get_dummies**</a> function in Pandas.\n",
    "\n",
    "Let's do this for some of the columns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_train_copy = titanic_train.copy() # save the state of your DF\n",
    "\n",
    "def one_hot(df, columns):\n",
    "    for column in columns:\n",
    "        # this means one-hot encode the column, and make the column title Pclass_{value}, for example\n",
    "        col_onehot = pd.get_dummies(df[column], prefix=column) \n",
    "        df.drop(column, axis=1, inplace=True)\n",
    "        df = df.join(col_onehot)\n",
    "    return df\n",
    "\n",
    "titanic_train_one_hot = one_hot(titanic_train_copy, ['Pclass', 'Sex', 'SibSp', 'Parch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_one_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The .get_dummies function will do nothing with missing values, so when one-hot encoding columns with missing values, create a dummy value for these missing values, so it will turn into a category that .get_dummies will create a column for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Floor'] = titanic_train['Floor'].fillna('null')\n",
    "pd.get_dummies(titanic_train['Floor'], prefix='Floor').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Clean the rest of the columns of the Titanic data set and use <a href=http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html>sklearn.LogisticRegression</a> to create a model for the 'Survived' column. Try it out on the `titanic_test` data and report your accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deeplearning)",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
